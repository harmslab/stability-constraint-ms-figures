{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "import os, inspect\n",
    "\n",
    "SMALL_SIZE = 20\n",
    "MEDIUM_SIZE = 24\n",
    "BIGGER_SIZE = 26\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=12)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=12)  # fontsize of the figure title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possible models to fit. \n",
    "def _linear_model(x, a=0.5):\n",
    "    return np.ones(len(x))*a\n",
    "\n",
    "def _exponential_model(x, a=1, k=0.1):\n",
    "    return a * np.exp(-k * x)\n",
    "\n",
    "#def _exponential_model(x, k=0.1):\n",
    "#    return np.exp(-k * x)\n",
    "\n",
    "def read_list_file(list_file,to_drop=[]):\n",
    "    \"\"\"\n",
    "    Load a sparky .list file. Return residue number and peak height.\n",
    "    \n",
    "    list_file: sparky .list file\n",
    "    to_drop: list of \"Assignment\" to drop (i.e. \"?-?\")\n",
    "    \n",
    "    returns dataframe with residue, height\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load file\n",
    "    df = pd.read_fwf(list_file)\n",
    "    \n",
    "    # Drop duplicants and nans\n",
    "    df = df.drop_duplicates()\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Drop anthing with assignment == something in to_drop\n",
    "    for drop in to_drop:\n",
    "        df = df.drop(df[df[\"Assignment\"]== drop].index)\n",
    "        \n",
    "    # Get residue number and height\n",
    "    df[\"residue\"] = [int(v.split(\"N-H\")[0][1:])\n",
    "                     for v in df.Assignment.values]\n",
    "    df[\"height\"] = df[\"Data Height\"]\n",
    "\n",
    "    # Return dataframe with only residue and height\n",
    "    return df.loc[:,[\"residue\",\"height\"]]\n",
    "\n",
    "def normalize(df,cutoff=2e5,manual_max=2e6,force_fast=[79,98,99,113],force_max_to_one=None):\n",
    "    \"\"\"\n",
    "    Normalize a set of heights for peaks to first peak. \n",
    "    \n",
    "    df: dataframe for single residue with time and height columns. normalizes\n",
    "        to height of first column.\n",
    "    cutoff: if maximum height is less than this, assume no real signal. \n",
    "    manual_max: if lower than cutoff, normalize to manual max\n",
    "    force_fast: for residues in list, force to be fast (normalize to manual_max\n",
    "                and set as fast).\n",
    "                \n",
    "    returns: dataframe with time, residue, normalized signal, height, and flag\n",
    "    where flag is \"fast\" or \"unknown\".\n",
    "    \"\"\"\n",
    "\n",
    "    time = []\n",
    "    norm = []\n",
    "    height = []\n",
    "    residue = []\n",
    "    flag = []\n",
    "    for i in np.unique(df.residue):\n",
    "\n",
    "        t = np.array(df.loc[df.residue == i,:].time)\n",
    "        h = np.array(df.loc[df.residue == i,:].height)\n",
    "        \n",
    "        if np.max(h) < cutoff or i in force_fast:\n",
    "            n = h/manual_max\n",
    "        else:\n",
    "            n = h/np.max(h)\n",
    "        \n",
    "        # Drop first point\n",
    "        n = n[1:]\n",
    "        t = t[1:]\n",
    "        h = h[1:]\n",
    "        \n",
    "        # For specific residues to normalize to one\n",
    "        if force_max_to_one is not None:\n",
    "            if i in force_max_to_one:\n",
    "                n = n/np.max(n)\n",
    "\n",
    "        time.extend(t)\n",
    "        norm.extend(n)\n",
    "        height.extend(h)\n",
    "        residue.extend([i for _ in range(len(t))])\n",
    "            \n",
    "        if np.max(h) < cutoff or i in force_fast:\n",
    "            flag.extend([\"fast\" for _ in range(len(t))])\n",
    "        else:\n",
    "            flag.extend([\"unknown\" for _ in range(len(t))])\n",
    "            \n",
    "        \n",
    "    return pd.DataFrame({\"time\":time,\n",
    "                         \"residue\":residue,\n",
    "                         \"norm\":norm,\n",
    "                         \"height\":height,\n",
    "                         \"flag\":flag})\n",
    "\n",
    "def load_hdx_expt(data_dir,\n",
    "                  to_drop=[\"?-?\",\"W88NE1-HE1\"],\n",
    "                  cutoff=2e5,\n",
    "                  manual_max=2e6,\n",
    "                  force_fast=[79,98,99,113],\n",
    "                  force_max_to_one=[]):\n",
    "    \"\"\"\n",
    "    Load an HDX experiment from data_dir. Assumes data_dir has timepoint.xlsx\n",
    "    and .list files. The .list files contain peaks and peak heights for each\n",
    "    timepoint. timepoint.xlsx gives the time at which each .list file was\n",
    "    collected.\n",
    "    \n",
    "    data_dir: directory with timepoint.xlsx and list files\n",
    "    to_drop: list of \"Assignment\" to drop (i.e. \"?-?\")\n",
    "    cutoff: if maximum height is less than this, assume no real signal when \n",
    "            normalizing. \n",
    "    manual_max: if max height lower than cutoff, normalize to manual max\n",
    "    force_fast: for residues in list, force to be fast (normalize to manual_max\n",
    "                and set as fast).\n",
    "    \n",
    "    returns: dataframe with time, residue, norm, height, and flag.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get list of timepoints and data files\n",
    "    df = pd.read_excel(os.path.join(data_dir,\"timepoints.xlsx\"))\n",
    "    \n",
    "    # Load datafiles and map timepoints\n",
    "    df_list = []\n",
    "    for i in range(len(df)):\n",
    "        row = df.iloc[i]\n",
    "        df_list.append(read_list_file(os.path.join(data_dir,row.file),\n",
    "                                      to_drop=to_drop))\n",
    "        df_list[-1][\"time\"] = row.time_in_minutes\n",
    "\n",
    "    # Return single dataframe with all results\n",
    "    final_df = pd.concat(df_list,ignore_index=True)\n",
    "    \n",
    "    for r in np.unique(final_df.residue):\n",
    "        this_df = final_df.loc[final_df.residue == r,:]\n",
    "        h = np.array(this_df.height)\n",
    "\n",
    "    final_df = final_df.loc[:,[\"time\",\"residue\",\"height\"]]\n",
    "    \n",
    "    return normalize(final_df,cutoff=cutoff,force_max_to_one=force_max_to_one)\n",
    "\n",
    "\n",
    "        \n",
    "def fit_hdx_aic(df,sigma2=0.00001,fig=None,ax=None,color=\"black\"):\n",
    "    \"\"\"\n",
    "    Fit a model to HDX data stored in df. Uses an AIC test to \n",
    "    decide what sort of model to fit. \n",
    "    \n",
    "    df: dataframe with with \"time\", \"norm\" and \"flag\" columns.\n",
    "    sigma2: squared error estimate for each normalized value (mainly affects\n",
    "            AIC test, with smaller values promoting more complicated model \n",
    "            selection). \n",
    "    fig: fig on which to plot (if None, create)\n",
    "    ax: ax on which to plot (if fig is None, will be created)\n",
    "    color: color for plot series.\n",
    "\n",
    "    returns: \n",
    "    \"\"\"\n",
    "\n",
    "    # Dictionary of models. \n",
    "    models = {\"linear\":_linear_model,\n",
    "              \"exponential\":_exponential_model}\n",
    "    \n",
    "    # Get time and norm values\n",
    "    t = np.array(df[\"time\"],dtype=float)\n",
    "    h = np.array(df[\"norm\"],dtype=float)\n",
    "    \n",
    "    # Only fit linear to fast exchanger -- drop possible exponential fit\n",
    "    if df.flag.iloc[0] == \"fast\":\n",
    "        models = {\"linear\":models[\"linear\"]}\n",
    "    \n",
    "    # Fit each model available\n",
    "    fits = []\n",
    "    for m in models:\n",
    "        \n",
    "        model = models[m]\n",
    "        \n",
    "        # Get signature of model to get appropriate guesses. All parameters \n",
    "        # constrained to be between 1e-12 and np.inf. \n",
    "        param = dict(inspect.signature(model).parameters)\n",
    "\n",
    "        bounds = [[],[]]\n",
    "        guesses = []\n",
    "        for p in param:\n",
    "            if param[p].default != inspect._empty:\n",
    "                guesses.append(param[p].default)\n",
    "                bounds[0].append(1e-12)\n",
    "                bounds[1].append(np.inf)\n",
    "            \n",
    "        # Try to fit model\n",
    "        try:\n",
    "            \n",
    "            # Do fit\n",
    "            opt, cov = curve_fit(model,t,h,\n",
    "                                 p0=guesses,\n",
    "                                 bounds=bounds,\n",
    "                                 sigma=np.ones(len(t))*np.sqrt(sigma2))\n",
    "\n",
    "            # Get num data points and num parameters\n",
    "            n = len(df)\n",
    "            k = len(opt)\n",
    "            \n",
    "            # calculate log likelihood\n",
    "            vals = model(t, *opt)\n",
    "            lnL = -0.5*(np.sum((h - vals)**2/sigma2 + np.log(sigma2)))\n",
    "            \n",
    "            # calculate AICc due to small sample size \n",
    "            # (https://en.wikipedia.org/wiki/Akaike_information_criterion)\n",
    "            AIC = 2*k - 2*lnL + (2*(k**2) + 2*k)/(n - k - 1)\n",
    "        \n",
    "            # Get fit parameter error\n",
    "            err = np.sqrt(np.diag(cov))\n",
    "\n",
    "        # If fit fails, print but keep going\n",
    "        except RuntimeError:\n",
    "            err = f\"could not fit {m}\\n\"\n",
    "            print(err)\n",
    "            continue\n",
    "            \n",
    "        # Record AIC, model, parameter names, estimates, and errors in list\n",
    "        fits.append((AIC,m,list(param.keys()),opt,err))\n",
    "    \n",
    "    # Sort by AIC (low to high)\n",
    "    fits.sort()\n",
    "    \n",
    "    # Get best scoring model \n",
    "    best = fits[0]\n",
    "    \n",
    "    # Create output dictionary keying parameter name to estimate and error\n",
    "    param_out = {}\n",
    "    for i in range(len(best[2][1:])):\n",
    "        p = best[2][i+1]\n",
    "        param_out[p] = (best[3][i],best[4][i])\n",
    "\n",
    "    # If fig/ax not passed, create new ones\n",
    "    if fig is None:\n",
    "        fig, ax = plt.subplots(1,figsize=(6,6))\n",
    "        \n",
    "    # Get model and parameter for plotting\n",
    "    model = models[best[1]]\n",
    "    param = best[3]\n",
    "    \n",
    "    # Plot fit\n",
    "    x = np.linspace(0,np.max(df[\"time\"])*1.1,1000)\n",
    "    ax.scatter(df[\"time\"],df[\"norm\"],facecolor=color,edgecolor=color,s=40)\n",
    "    ax.plot(x,model(x,*param),\"-\",lw=3,color=color)\n",
    "   \n",
    "    # Figure out what type of fit this is (exponential, fast, or slow). \n",
    "    flag = best[1]    \n",
    "    if flag == \"linear\":\n",
    "        if param_out[\"a\"][0] < 0.1:\n",
    "            flag = \"fast\"\n",
    "        else:\n",
    "            flag = \"slow\"\n",
    "    \n",
    "    \n",
    "    return param_out, flag, fig, ax\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "a9 = load_hdx_expt(\"input-data/a9/\",force_max_to_one=[79])\n",
    "m63f = load_hdx_expt(\"input-data/m63f/\",force_max_to_one=[38,39])\n",
    "\n",
    "# Define figure size\n",
    "fig_width=7\n",
    "fig_height=10\n",
    "\n",
    "# Figure out how many rows and columns to have to fit inside figure \n",
    "# dimensions gracefully\n",
    "num_graphs = len(np.unique(a9.residue))\n",
    "aspect_ratio = fig_width/fig_height\n",
    "num_rows = np.sqrt(num_graphs/aspect_ratio)\n",
    "num_rows = int(np.round(num_rows,0))\n",
    "num_cols = int(np.ceil(num_graphs/num_rows))\n",
    "\n",
    "label_reducer = {\"exponential\":\"e\",\n",
    "                 \"fast\":\"f\",\n",
    "                 \"slow\":\"r\"}\n",
    "\n",
    "# Create plot\n",
    "fig, ax = plt.subplots(num_rows,num_cols,figsize=(fig_width,fig_height))\n",
    "\n",
    "# Find max/min for all plots\n",
    "max_time = np.max((np.max(a9.time),np.max(m63f.time)))*1.05\n",
    "min_height = np.min((np.min(a9.height),np.min(m63f.height)))*1.05\n",
    "max_height = np.max((np.max(a9.height),np.max(m63f.height)))*1.05\n",
    "\n",
    "# Get overall min/max for plots\n",
    "xlim = (-100,max_time)\n",
    "ylim = (-0.1,1.2)\n",
    "\n",
    "# Dictionary will hold all output and be converted to a dataframe\n",
    "out = {\"residue\":[],\"protein\":[],\"flag\":[],\n",
    "       \"a\":[],\"a_err\":[],\n",
    "       \"k\":[],\"k_err\":[]}\n",
    "\n",
    "# Go through all unique residues in a9\n",
    "row = 0\n",
    "col = 0\n",
    "\n",
    "# Make first empty so we can add axes in illustrator\n",
    "ax[row,col].set_xlim(xlim)\n",
    "ax[row,col].set_ylim(ylim)\n",
    "ax[row,col].set_axis_off()\n",
    "\n",
    "col += 1\n",
    "\n",
    "\n",
    "\n",
    "for r in np.unique(a9.residue):\n",
    "    \n",
    "    # Fit A9 for this residue\n",
    "    a9_df = a9.loc[a9.residue == r,:]\n",
    "    if len(a9_df) > 0:\n",
    "    \n",
    "        param, flag, _, _ = fit_hdx_aic(a9_df,\n",
    "                                        fig=fig,\n",
    "                                        ax=ax[row,col],\n",
    "                                        color=\"black\")\n",
    "        \n",
    "        # New entry for this residue\n",
    "        out[\"residue\"].append(r)\n",
    "        out[\"protein\"].append(\"hS100A9\")\n",
    "        out[\"flag\"].append(flag)\n",
    "        out[\"a\"].append(np.nan)\n",
    "        out[\"a_err\"].append(np.nan)\n",
    "        out[\"k\"].append(np.nan)\n",
    "        out[\"k_err\"].append(np.nan)\n",
    "        \n",
    "        # Populate parameters from the model that came out\n",
    "        for p in param:\n",
    "            out[p][-1] = param[p][0]\n",
    "            out[f\"{p}_err\"][-1] = param[p][1]\n",
    "        \n",
    "    # Fig M63F for this residue\n",
    "    m63f_df = m63f.loc[m63f.residue == r,:]\n",
    "    if len(m63f_df) > 0:\n",
    "        \n",
    "        param, flag, _, _ = fit_hdx_aic(m63f_df,\n",
    "                                        fig=fig,\n",
    "                                        ax=ax[row,col],\n",
    "                                        color=\"orange\")\n",
    "        # New entry for this residue\n",
    "        out[\"residue\"].append(r)\n",
    "        out[\"protein\"].append(\"hS100A9/M63F\")\n",
    "        out[\"flag\"].append(flag)\n",
    "        out[\"a\"].append(np.nan)\n",
    "        out[\"a_err\"].append(np.nan)\n",
    "        out[\"k\"].append(np.nan)\n",
    "        out[\"k_err\"].append(np.nan)\n",
    "\n",
    "        # Populate parameters from the model that came out\n",
    "        for p in param:\n",
    "            out[p][-1] = param[p][0]\n",
    "            out[f\"{p}_err\"][-1] = param[p][1]\n",
    "    \n",
    "    # set plot limits etc.\n",
    "    ax[row,col].set_xlim(xlim)\n",
    "    ax[row,col].set_ylim(ylim)\n",
    "    ax[row,col].set_title(f\"{r}: {out['flag'][-2][0]}/{out['flag'][-1][0]}\")\n",
    "    ax[row,col].set_axis_off()\n",
    "    \n",
    "    # Incremet ax for fit\n",
    "    col += 1\n",
    "    if col == num_cols:\n",
    "        row += 1\n",
    "        col = 0\n",
    "    \n",
    "# Clear any remaining emtpy ax\n",
    "while row < num_rows:\n",
    "    ax[row,col].set_axis_off()\n",
    "    col += 1\n",
    "    if col == num_cols:\n",
    "        row += 1\n",
    "        col = 0\n",
    "    \n",
    "# Clean up as dispaly figure and write out\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figure_s3.pdf\")\n",
    "\n",
    "# Convert fit values to a dataframe\n",
    "df = pd.DataFrame(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_residues(df):\n",
    "    \"\"\"\n",
    "    Compare the exchange for all residues seen in A9 and M63F. \n",
    "    \n",
    "    df: dataframe output from cell above (residue, protein, flag, a, a_err, k, k_err)\n",
    "    \n",
    "    returns: dataframe with a row for each residue. columns hold qualitative \n",
    "             change (slower, faster, unchanged), quantitive change if calculable \n",
    "             (dlnK), quantitive error, and flags for A9 and M63F\n",
    "    \"\"\"\n",
    "\n",
    "    # Lists to hold output for conversion to dataframe\n",
    "    residue = []\n",
    "    effect = []\n",
    "    qualitative = []\n",
    "    quantitative = []\n",
    "    quant_err = []\n",
    "    \n",
    "    # Go through residues\n",
    "    for r in np.unique(df.residue):\n",
    "\n",
    "        residue.append(r)\n",
    "        this_df = df.loc[df.residue == r]\n",
    "\n",
    "        # Figure out effect (flag -> flag)\n",
    "        if len(this_df) != 2:\n",
    "            effect.append((\"fast\",\"missing\"))\n",
    "        else:\n",
    "            effect.append((this_df.flag.iloc[0],\n",
    "                           this_df.flag.iloc[1]))\n",
    "\n",
    "        # For residues where both A9 and M63F fit, calculate ln(k2/k1) and \n",
    "        # error\n",
    "        if \"-\".join(effect[-1]) == \"exponential-exponential\":\n",
    "\n",
    "            # lnK1 is M63F. \n",
    "            lnK1 = np.log(this_df.k.iloc[1])\n",
    "            \n",
    "            # For error, subtract and add. For non-negative values,\n",
    "            # take log. \n",
    "            e1u = this_df.k.iloc[1] + this_df.k_err.iloc[1]\n",
    "            e1l = this_df.k.iloc[1] - this_df.k_err.iloc[1]\n",
    "            estack = []\n",
    "            if e1u > 0:\n",
    "                estack.append(np.log(e1u))\n",
    "            if e1l > 0:\n",
    "                estack.append(np.log(e1l))\n",
    "\n",
    "            # Final error is abs(lnK - mean_error)*1.96 --> 95% confidence\n",
    "            e1 = np.abs(lnK1 - np.mean(estack))*1.96\n",
    "\n",
    "            # lnK0 is A9. Repeat error as for M63F\n",
    "            lnK0 = np.log(this_df.k.iloc[0])\n",
    "            e0u = this_df.k.iloc[0] + this_df.k_err.iloc[0]\n",
    "            e0l = this_df.k.iloc[0] - this_df.k_err.iloc[0]\n",
    "            estack = []\n",
    "            if e0u > 0:\n",
    "                estack.append(np.log(e0u))\n",
    "            if e0l > 0:\n",
    "                estack.append(np.log(e0l))\n",
    "            e0 = np.abs(lnK0 - np.mean(estack))*1.96\n",
    "\n",
    "            # Record quantitative difference in lnK as well as propagated error\n",
    "            quantitative.append(lnK1 - lnK0)\n",
    "            quant_err.append(np.sqrt(e1**2 + e0**2))\n",
    "        else:\n",
    "            quantitative.append(np.nan)\n",
    "            quant_err.append(np.nan)\n",
    "\n",
    "        # Look for times when M63F is *slower* than A9, not quantitative\n",
    "        if \"-\".join(effect[-1]) in [\"fast-exponential\",\n",
    "                                    \"exponential-slow\",\n",
    "                                    \"fast-slow\"]:\n",
    "            qualitative.append(\"slower\")\n",
    "            \n",
    "        # Look for times when M63F is *faster* than A9, not quantitative\n",
    "        elif \"-\".join(effect[-1]) in [\"slow-exponential\",\n",
    "                                      \"exponential-fast\",\n",
    "                                      \"slow-fast\"]:\n",
    "            qualitative.append(\"faster\")\n",
    "            \n",
    "        # Map quantitative results to qualitative slower/faster axis\n",
    "        elif \"-\".join(effect[-1]) == \"exponential-exponential\":\n",
    "            if quantitative[-1] < 0:\n",
    "                qualitative.append(\"slower\")\n",
    "            else:\n",
    "                qualitative.append(\"faster\")\n",
    "\n",
    "        # No change \n",
    "        else:\n",
    "            qualitative.append(\"unchanged\")\n",
    "\n",
    "    return pd.DataFrame({\"residue\":residue,\n",
    "                         \"qualitative\":qualitative,\n",
    "                         \"quantitative\":quantitative,\n",
    "                         \"quant_err\":quant_err,\n",
    "                         \"a9\":[e[0] for e in effect],\n",
    "                         \"m63f\":[e[1] for e in effect]})\n",
    "\n",
    "\n",
    "summary_df = compare_residues(df)\n",
    "summary_df.to_csv(\"table_s5.csv\")\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RT = 0.001987*298\n",
    "\n",
    "fig, ax = plt.subplots(1,figsize=(15,7))\n",
    "\n",
    "line_x = []\n",
    "line_y = []\n",
    "for r in np.unique(summary_df.residue):\n",
    "    row = summary_df.loc[summary_df.residue == r,:].iloc[0]\n",
    "\n",
    "    if row.qualitative == \"slower\":\n",
    "        ax.arrow(r,4,0,-0.1,color=\"blue\",head_width=.5,width=0.4)\n",
    "        \n",
    "        if np.logical_not(np.isnan(row.quantitative)):\n",
    "            value = row.quantitative*RT\n",
    "            ax.scatter(r,value,s=200,facecolor=\"none\",edgecolor=\"blue\")\n",
    "            ax.errorbar(x=r,y=value,yerr=row.quant_err*RT,color=\"blue\",capsize=10,lw=2)\n",
    "\n",
    "\n",
    "    if row.qualitative == \"faster\":\n",
    "        ax.arrow(r,4,0,0.1,color=\"red\",head_width=.5,width=0.4)\n",
    "        if np.logical_not(np.isnan(row.quantitative)):\n",
    "            value = row.quantitative*RT\n",
    "            ax.scatter(r,value,s=200,facecolor=\"none\",edgecolor=\"red\")\n",
    "            ax.errorbar(x=r,y=value,yerr=row.quant_err*RT,color=\"red\",capsize=10,lw=2)\n",
    "            \n",
    "    if row.qualitative == \"unchanged\":\n",
    "        value = None\n",
    "        ax.scatter(r,4,s=30,color=\"gray\",marker=\"s\")\n",
    "\n",
    "    if value is not None:\n",
    "        \n",
    "        if len(line_x) > 0:\n",
    "            if line_x[-1][-1] == (r - 1):\n",
    "                line_x[-1].append(r)\n",
    "                line_y[-1].append(value)\n",
    "            else:\n",
    "                line_x.append([r])\n",
    "                line_y.append([value])\n",
    "        else:\n",
    "            line_x.append([r])\n",
    "            line_y.append([value])\n",
    "        \n",
    "ax.plot((0,114),(0,0),\"--\",color=\"gray\")\n",
    "ax.set_xlabel(\"residue\")\n",
    "ax.set_ylabel(\"-RTln(k_{M63F}/k_{A9})\")\n",
    "fig.savefig(\"figure_s4b.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys, values = np.unique([f\"{a[0]}-{a[1]}\" for a in zip(summary_df.a9,summary_df.m63f)],return_counts=True)\n",
    "\n",
    "count_dict = dict(zip(keys,values))\n",
    "\n",
    "labels = [\"fast-exponential\",\n",
    "          \"exponential-exponential\",\n",
    "          #\"exponential-slow\",\n",
    "          \"slow-fast\",\n",
    "          \"exponential-fast\",\n",
    "          \"fast-fast\",\n",
    "          \"slow-slow\",\n",
    "          \"fast-missing\"]\n",
    "\n",
    "color_map = {\"fast-exponential\":(0.,0.5,1),\n",
    "             \"exponential-exponential\":(0.,0.3,1),\n",
    "             \"exponential-slow\":(0.,0.1,1),\n",
    "             \"slow-fast\":(1,0,0),    \n",
    "             \"exponential-fast\":(1,0.5,0),\n",
    "             \"fast-fast\":(0.5,0.5,0.5),\n",
    "             \"slow-slow\":(0.3,0.3,0.3),\n",
    "             \"fast-missing\":(0.1,0.1,0.1)}\n",
    "             \n",
    "fig, ax = plt.subplots(1,figsize=(6,6))\n",
    "\n",
    "_ = ax.pie([count_dict[l] for l in labels],\n",
    "           labels=[\" to \".join(l.split(\"-\")) for l in labels],\n",
    "           colors=[color_map[l] for l in labels])\n",
    "\n",
    "fig.savefig(\"figure_s4a.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,figsize=(6,6))\n",
    "\n",
    "\n",
    "markers = [\"o\",\"v\",\"s\",\"D\"]\n",
    "colors = [(0,0,1),(0.5,0.5,1),(0.7,0.7,1)]\n",
    "for i, r in enumerate([37]): \n",
    "    a9_r = a9.loc[a9.residue == r,:]\n",
    "    m63f_r = m63f.loc[m63f.residue == r,:]\n",
    "        \n",
    "    \n",
    "        \n",
    "    fit_values = df.loc[df.residue == r,:]\n",
    "    \n",
    "    ax.scatter(a9_r.time,a9_r.norm,s=100,facecolor=\"none\",edgecolor=\"black\",marker=markers[i])\n",
    "    ax.scatter(m63f_r.time,m63f_r.norm,s=100,facecolor=\"none\",edgecolor=colors[i],marker=markers[i])\n",
    "    \n",
    "    t = np.linspace(0,np.max(a9_r.time)*1.1)\n",
    "    ax.plot(t,_exponential_model(t,fit_values.a.iloc[0],fit_values.k.iloc[0]),color=\"black\",lw=3)\n",
    "    ax.plot(t,_exponential_model(t,fit_values.a.iloc[1],fit_values.k.iloc[1]),color=colors[i],lw=3)\n",
    "    #ax.plot(t,_exponential_model(t,fit_values.k.iloc[0]),color=\"black\",lw=3)\n",
    "    #ax.plot(t,_exponential_model(t,fit_values.k.iloc[1]),color=\"orange\",lw=3)\n",
    "\n",
    "ax.set_xlabel(\"time (min.)\")\n",
    "ax.set_ylabel(\"fx original height\")\n",
    "fig.savefig(\"fig_4c.pdf\")\n",
    "#ax.set_xscale(\"log\")\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
